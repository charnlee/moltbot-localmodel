# Moltbot vLLM Local Plugin ğŸš€

<div align="center">

**è¿æ¥æœ¬åœ° vLLM éƒ¨ç½²çš„æ¨¡å‹**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

</div>

---

## ğŸ“– ç®€ä»‹

è¿™æ˜¯ä¸€ä¸ª Moltbot æ’ä»¶ï¼Œè®©ä½ å¯ä»¥è½»æ¾è¿æ¥æœ¬åœ° vLLM éƒ¨ç½²çš„æ¨¡å‹ã€‚åªéœ€è¦è¾“å…¥ base URL å’Œ model åå­—ï¼Œå°±å¯ä»¥å¼€å§‹ä½¿ç”¨ï¼

### âœ¨ ç‰¹æ€§

- âœ… æ”¯æŒä»»ä½• vLLM éƒ¨ç½²çš„æ¨¡å‹
- âœ… OpenAI å…¼å®¹ API
- âœ… æ”¯æŒå¤šä¸ªæ¨¡å‹å®ä¾‹
- âœ… ç®€å•é…ç½®ï¼ˆbase URL + model åå­—ï¼‰
- âœ… å¯é€‰ API Key è®¤è¯
- âœ… è‡ªåŠ¨é…ç½®ä¸Šä¸‹æ–‡çª—å£å’Œæœ€å¤§ token

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…

```bash
# ä»æœ¬åœ°å®‰è£…
cd vllm-local
npm install
npm run build
moltbot plugins install .

# æˆ–ä» NPM å®‰è£…
moltbot plugins install @moltbot-china/vllm-local
```

### é…ç½®

#### æ–¹å¼ 1: ä½¿ç”¨å‘½ä»¤è¡Œé…ç½®ï¼ˆæ¨èï¼‰

```bash
moltbot models auth login --provider vllm-local
```

ä¼šæç¤ºä½ è¾“å…¥ï¼š
- Base URL (å¦‚: http://tanglian.bodesitech.com:8000)
- Model åå­— (å¦‚: Qwen3-32B)
- API Key (å¯é€‰ï¼Œç›´æ¥å›è½¦è·³è¿‡)

#### æ–¹å¼ 2: æ‰‹åŠ¨ç¼–è¾‘é…ç½®æ–‡ä»¶

ç¼–è¾‘ `~/.clawdbot/config.json5`:

```json5
{
  plugins: {
    entries: {
      "vllm-local": {
        enabled: true
      }
    }
  },
  models: {
    providers: {
      "vllm-local": {
        baseUrl: "http://tanglian.bodesitech.com:8000",
        api: "openai-completions",
        models: [
          {
            id: "Qwen3-32B",
            name: "Qwen3-32B (Local vLLM)",
            api: "openai-completions",
            reasoning: false,
            input: ["text"],
            cost: {
              input: 0,      // æœ¬åœ°æ¨¡å‹æ— æˆæœ¬
              output: 0,
              cacheRead: 0,
              cacheWrite: 0
            },
            contextWindow: 32768,
            maxTokens: 4096
          }
        ]
      }
    }
  },
  agents: {
    defaults: {
      model: "vllm-local/Qwen3-32B"
    }
  }
}
```

### ä½¿ç”¨

```bash
# ä½¿ç”¨é»˜è®¤æ¨¡å‹
moltbot agent --message "ä½ å¥½ï¼Œä½ æ˜¯å“ªä¸ªæ¨¡å‹ï¼Ÿ"

# æŒ‡å®šæ¨¡å‹
moltbot agent --model vllm-local/Qwen3-32B --message "ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"

# é€šè¿‡æ¶ˆæ¯é€šé“ä½¿ç”¨
# åœ¨é£ä¹¦/Telegram ç­‰æ¸ é“å‘é€æ¶ˆæ¯å³å¯
```

## ğŸ“š é…ç½®è¯´æ˜

### Base URL

ä½ çš„ vLLM æœåŠ¡å™¨åœ°å€ï¼Œä¾‹å¦‚ï¼š
- `http://localhost:8000` - æœ¬åœ°éƒ¨ç½²
- `http://192.168.1.100:8000` - å±€åŸŸç½‘
- `http://tanglian.bodesitech.com:8000` - è¿œç¨‹æœåŠ¡å™¨

**æ³¨æ„**ï¼šä¸è¦åœ¨ URL æœ«å°¾åŠ  `/v1`ï¼Œæ’ä»¶ä¼šè‡ªåŠ¨æ·»åŠ ã€‚

### Model åå­—

ä½ åœ¨ vLLM ä¸­éƒ¨ç½²çš„æ¨¡å‹åç§°ï¼Œä¾‹å¦‚ï¼š
- `Qwen3-32B`
- `Qwen2.5-72B-Instruct`
- `Meta-Llama-3-70B`
- ä»»ä½•å…¶ä»–æ¨¡å‹å

### API Keyï¼ˆå¯é€‰ï¼‰

å¦‚æœä½ çš„ vLLM æœåŠ¡å™¨éœ€è¦è®¤è¯ï¼Œå¯ä»¥è®¾ç½® API Keyã€‚

## ğŸ”§ é«˜çº§é…ç½®

### é…ç½®å¤šä¸ªæ¨¡å‹

```json5
{
  models: {
    providers: {
      "vllm-local": {
        baseUrl: "http://tanglian.bodesitech.com:8000",
        models: [
          {
            id: "Qwen3-32B",
            name: "Qwen3-32B",
            contextWindow: 32768,
            maxTokens: 4096,
            // ... å…¶ä»–é…ç½®
          },
          {
            id: "Qwen2.5-72B-Instruct",
            name: "Qwen2.5-72B (Larger)",
            contextWindow: 131072,
            maxTokens: 8192,
            // ... å…¶ä»–é…ç½®
          }
        ]
      }
    }
  }
}
```

### é…ç½®å¤šä¸ª vLLM å®ä¾‹

```json5
{
  models: {
    providers: {
      "vllm-local-1": {
        baseUrl: "http://server1:8000",
        models: [...]
      },
      "vllm-local-2": {
        baseUrl: "http://server2:8000",
        models: [...]
      }
    }
  }
}
```

## ğŸ§ª æµ‹è¯•

### æµ‹è¯•è¿æ¥

```bash
# åˆ—å‡ºå¯ç”¨æ¨¡å‹
moltbot models list

# æµ‹è¯•å‘é€æ¶ˆæ¯
moltbot agent --model vllm-local/Qwen3-32B --message "ä½ å¥½"
```

### ä½¿ç”¨ curl æµ‹è¯• vLLM æœåŠ¡å™¨

```bash
curl --request POST \
  --url http://tanglian.bodesitech.com:8000/v1/chat/completions \
  --header 'Content-Type: application/json' \
  --data '{
    "model": "Qwen3-32B",
    "messages": [
      {
        "role": "user",
        "content": "ä½ å¥½ï¼Œä½ æ˜¯å“ªä¸ªæ¨¡å‹ï¼Ÿ"
      }
    ]
  }'
```

## ğŸ“ vLLM éƒ¨ç½²å‚è€ƒ

### å¯åŠ¨ vLLM æœåŠ¡å™¨

```bash
# åŸºç¡€å¯åŠ¨
python -m vllm.entrypoints.openai.api_server \
  --model Qwen/Qwen2.5-32B-Instruct \
  --served-model-name Qwen3-32B \
  --host 0.0.0.0 \
  --port 8000

# å¸¦ GPU é…ç½®
python -m vllm.entrypoints.openai.api_server \
  --model Qwen/Qwen2.5-32B-Instruct \
  --served-model-name Qwen3-32B \
  --host 0.0.0.0 \
  --port 8000 \
  --gpu-memory-utilization 0.9 \
  --max-model-len 32768
```

---

<div align="center">
Made with â¤ï¸ for the Moltbot community
</div>
